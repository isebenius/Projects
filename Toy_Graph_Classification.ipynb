{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toy Graph Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isebenius/Projects/blob/master/Toy_Graph_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn5U4EE6K86v"
      },
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHSP6-RBOqCE"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
        "data = dataset[0]  # Get the first graph object.\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j11WiUr-PRH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f677c35-c184-416b-a014-c3bde7c73259"
      },
      "source": [
        "torch.manual_seed(12345)\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "train_dataset = dataset[:150]\n",
        "test_dataset = dataset[150:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training graphs: 150\n",
            "Number of test graphs: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gZ-l0npPIca"
      },
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN3sRVuaQ88l"
      },
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvhgQoO8Svw4"
      },
      "source": [
        "from IPython.display import Javascript\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
        "         loss = criterion(out, data.y)  # Compute the loss.\n",
        "         loss.backward()  # Derive gradients.\n",
        "         optimizer.step()  # Update parameters based on gradients.\n",
        "         optimizer.zero_grad()  # Clear gradients.\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  \n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNgkR8SRaU_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f37d51-0bcd-45ab-d9e2-02b67bee31fe"
      },
      "source": [
        "from torch_geometric.nn import GraphConv\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)  # TODO\n",
        "        self.conv2 = GraphConv(hidden_channels, hidden_channels)  # TODO\n",
        "        self.conv3 = GraphConv(hidden_channels, hidden_channels)  # TODO\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = GNN(hidden_channels=64)\n",
        "print(model)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): GraphConv(7, 64)\n",
            "  (conv2): GraphConv(64, 64)\n",
            "  (conv3): GraphConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs5D713Ia_Sv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "eca3271e-9082-4597-f65a-b3afc6ca48ea"
      },
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = GNN(hidden_channels=64)\n",
        "print(model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GNN(\n",
            "  (conv1): GraphConv(7, 64)\n",
            "  (conv2): GraphConv(64, 64)\n",
            "  (conv3): GraphConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 001, Train Acc: 0.3133, Test Acc: 0.4211\n",
            "Epoch: 002, Train Acc: 0.6867, Test Acc: 0.5789\n",
            "Epoch: 003, Train Acc: 0.6867, Test Acc: 0.5789\n",
            "Epoch: 004, Train Acc: 0.6867, Test Acc: 0.5789\n",
            "Epoch: 005, Train Acc: 0.6867, Test Acc: 0.5789\n",
            "Epoch: 006, Train Acc: 0.6867, Test Acc: 0.5789\n",
            "Epoch: 007, Train Acc: 0.6867, Test Acc: 0.5789\n",
            "Epoch: 008, Train Acc: 0.7067, Test Acc: 0.6579\n",
            "Epoch: 009, Train Acc: 0.7333, Test Acc: 0.7368\n",
            "Epoch: 010, Train Acc: 0.7333, Test Acc: 0.7368\n",
            "Epoch: 011, Train Acc: 0.7400, Test Acc: 0.7632\n",
            "Epoch: 012, Train Acc: 0.7933, Test Acc: 0.8158\n",
            "Epoch: 013, Train Acc: 0.7533, Test Acc: 0.7632\n",
            "Epoch: 014, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 015, Train Acc: 0.7667, Test Acc: 0.8684\n",
            "Epoch: 016, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 017, Train Acc: 0.7800, Test Acc: 0.7895\n",
            "Epoch: 018, Train Acc: 0.7800, Test Acc: 0.8158\n",
            "Epoch: 019, Train Acc: 0.7933, Test Acc: 0.8158\n",
            "Epoch: 020, Train Acc: 0.7933, Test Acc: 0.8158\n",
            "Epoch: 021, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 022, Train Acc: 0.7600, Test Acc: 0.7895\n",
            "Epoch: 023, Train Acc: 0.8000, Test Acc: 0.8158\n",
            "Epoch: 024, Train Acc: 0.7667, Test Acc: 0.8684\n",
            "Epoch: 025, Train Acc: 0.8067, Test Acc: 0.8158\n",
            "Epoch: 026, Train Acc: 0.8067, Test Acc: 0.8158\n",
            "Epoch: 027, Train Acc: 0.7933, Test Acc: 0.7895\n",
            "Epoch: 028, Train Acc: 0.8200, Test Acc: 0.7895\n",
            "Epoch: 029, Train Acc: 0.8200, Test Acc: 0.7895\n",
            "Epoch: 030, Train Acc: 0.8200, Test Acc: 0.7632\n",
            "Epoch: 031, Train Acc: 0.7933, Test Acc: 0.7632\n",
            "Epoch: 032, Train Acc: 0.7933, Test Acc: 0.7368\n",
            "Epoch: 033, Train Acc: 0.8067, Test Acc: 0.8158\n",
            "Epoch: 034, Train Acc: 0.7867, Test Acc: 0.8421\n",
            "Epoch: 035, Train Acc: 0.8133, Test Acc: 0.7895\n",
            "Epoch: 036, Train Acc: 0.8267, Test Acc: 0.7632\n",
            "Epoch: 037, Train Acc: 0.7733, Test Acc: 0.8684\n",
            "Epoch: 038, Train Acc: 0.8267, Test Acc: 0.7632\n",
            "Epoch: 039, Train Acc: 0.7733, Test Acc: 0.7895\n",
            "Epoch: 040, Train Acc: 0.7867, Test Acc: 0.8158\n",
            "Epoch: 041, Train Acc: 0.7867, Test Acc: 0.7105\n",
            "Epoch: 042, Train Acc: 0.8000, Test Acc: 0.8158\n",
            "Epoch: 043, Train Acc: 0.8133, Test Acc: 0.7895\n",
            "Epoch: 044, Train Acc: 0.8133, Test Acc: 0.7895\n",
            "Epoch: 045, Train Acc: 0.8267, Test Acc: 0.7632\n",
            "Epoch: 046, Train Acc: 0.8733, Test Acc: 0.7368\n",
            "Epoch: 047, Train Acc: 0.8600, Test Acc: 0.8421\n",
            "Epoch: 048, Train Acc: 0.8600, Test Acc: 0.7105\n",
            "Epoch: 049, Train Acc: 0.8200, Test Acc: 0.8421\n",
            "Epoch: 050, Train Acc: 0.8400, Test Acc: 0.6579\n",
            "Epoch: 051, Train Acc: 0.8667, Test Acc: 0.7105\n",
            "Epoch: 052, Train Acc: 0.8133, Test Acc: 0.6842\n",
            "Epoch: 053, Train Acc: 0.8400, Test Acc: 0.7895\n",
            "Epoch: 054, Train Acc: 0.8133, Test Acc: 0.6579\n",
            "Epoch: 055, Train Acc: 0.8467, Test Acc: 0.7895\n",
            "Epoch: 056, Train Acc: 0.8867, Test Acc: 0.7105\n",
            "Epoch: 057, Train Acc: 0.8800, Test Acc: 0.7368\n",
            "Epoch: 058, Train Acc: 0.8933, Test Acc: 0.8421\n",
            "Epoch: 059, Train Acc: 0.9000, Test Acc: 0.7632\n",
            "Epoch: 060, Train Acc: 0.9133, Test Acc: 0.8158\n",
            "Epoch: 061, Train Acc: 0.9267, Test Acc: 0.8158\n",
            "Epoch: 062, Train Acc: 0.8933, Test Acc: 0.7368\n",
            "Epoch: 063, Train Acc: 0.8933, Test Acc: 0.7632\n",
            "Epoch: 064, Train Acc: 0.8800, Test Acc: 0.7368\n",
            "Epoch: 065, Train Acc: 0.9267, Test Acc: 0.7632\n",
            "Epoch: 066, Train Acc: 0.9067, Test Acc: 0.7368\n",
            "Epoch: 067, Train Acc: 0.9400, Test Acc: 0.8158\n",
            "Epoch: 068, Train Acc: 0.9333, Test Acc: 0.8158\n",
            "Epoch: 069, Train Acc: 0.9467, Test Acc: 0.8947\n",
            "Epoch: 070, Train Acc: 0.8800, Test Acc: 0.7632\n",
            "Epoch: 071, Train Acc: 0.9467, Test Acc: 0.8684\n",
            "Epoch: 072, Train Acc: 0.9333, Test Acc: 0.7368\n",
            "Epoch: 073, Train Acc: 0.9333, Test Acc: 0.7895\n",
            "Epoch: 074, Train Acc: 0.9267, Test Acc: 0.7895\n",
            "Epoch: 075, Train Acc: 0.9533, Test Acc: 0.7632\n",
            "Epoch: 076, Train Acc: 0.9400, Test Acc: 0.7632\n",
            "Epoch: 077, Train Acc: 0.9533, Test Acc: 0.8421\n",
            "Epoch: 078, Train Acc: 0.9467, Test Acc: 0.8158\n",
            "Epoch: 079, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 080, Train Acc: 0.9400, Test Acc: 0.7895\n",
            "Epoch: 081, Train Acc: 0.9400, Test Acc: 0.7895\n",
            "Epoch: 082, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 083, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 084, Train Acc: 0.9467, Test Acc: 0.8158\n",
            "Epoch: 085, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 086, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 087, Train Acc: 0.9400, Test Acc: 0.7895\n",
            "Epoch: 088, Train Acc: 0.9200, Test Acc: 0.7895\n",
            "Epoch: 089, Train Acc: 0.9400, Test Acc: 0.8158\n",
            "Epoch: 090, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 091, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 092, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 093, Train Acc: 0.9400, Test Acc: 0.7895\n",
            "Epoch: 094, Train Acc: 0.9467, Test Acc: 0.7632\n",
            "Epoch: 095, Train Acc: 0.9333, Test Acc: 0.8421\n",
            "Epoch: 096, Train Acc: 0.9267, Test Acc: 0.7632\n",
            "Epoch: 097, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 098, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 099, Train Acc: 0.8800, Test Acc: 0.6842\n",
            "Epoch: 100, Train Acc: 0.9400, Test Acc: 0.8421\n",
            "Epoch: 101, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 102, Train Acc: 0.9400, Test Acc: 0.7632\n",
            "Epoch: 103, Train Acc: 0.9467, Test Acc: 0.8684\n",
            "Epoch: 104, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 105, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 106, Train Acc: 0.9467, Test Acc: 0.8158\n",
            "Epoch: 107, Train Acc: 0.9533, Test Acc: 0.7632\n",
            "Epoch: 108, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 109, Train Acc: 0.9467, Test Acc: 0.8421\n",
            "Epoch: 110, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 111, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 112, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 113, Train Acc: 0.9667, Test Acc: 0.7632\n",
            "Epoch: 114, Train Acc: 0.9400, Test Acc: 0.8684\n",
            "Epoch: 115, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 116, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 117, Train Acc: 0.9467, Test Acc: 0.8158\n",
            "Epoch: 118, Train Acc: 0.9333, Test Acc: 0.7632\n",
            "Epoch: 119, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 120, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 121, Train Acc: 0.9467, Test Acc: 0.8158\n",
            "Epoch: 122, Train Acc: 0.9600, Test Acc: 0.7368\n",
            "Epoch: 123, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 124, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 125, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 126, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 127, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 128, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 129, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 130, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 131, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 132, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 133, Train Acc: 0.9467, Test Acc: 0.8421\n",
            "Epoch: 134, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 135, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 136, Train Acc: 0.9400, Test Acc: 0.7368\n",
            "Epoch: 137, Train Acc: 0.9600, Test Acc: 0.7632\n",
            "Epoch: 138, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 139, Train Acc: 0.9467, Test Acc: 0.7632\n",
            "Epoch: 140, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 141, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 142, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 143, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 144, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 145, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 146, Train Acc: 0.9667, Test Acc: 0.7632\n",
            "Epoch: 147, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 148, Train Acc: 0.9467, Test Acc: 0.8158\n",
            "Epoch: 149, Train Acc: 0.9733, Test Acc: 0.8158\n",
            "Epoch: 150, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 151, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 152, Train Acc: 0.9667, Test Acc: 0.7368\n",
            "Epoch: 153, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 154, Train Acc: 0.9333, Test Acc: 0.7632\n",
            "Epoch: 155, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 156, Train Acc: 0.9133, Test Acc: 0.8947\n",
            "Epoch: 157, Train Acc: 0.9467, Test Acc: 0.8158\n",
            "Epoch: 158, Train Acc: 0.9533, Test Acc: 0.7632\n",
            "Epoch: 159, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 160, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 161, Train Acc: 0.9467, Test Acc: 0.7895\n",
            "Epoch: 162, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 163, Train Acc: 0.9733, Test Acc: 0.8158\n",
            "Epoch: 164, Train Acc: 0.9667, Test Acc: 0.8158\n",
            "Epoch: 165, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 166, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 167, Train Acc: 0.9533, Test Acc: 0.8684\n",
            "Epoch: 168, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 169, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 170, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 171, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 172, Train Acc: 0.9667, Test Acc: 0.7895\n",
            "Epoch: 173, Train Acc: 0.9733, Test Acc: 0.7895\n",
            "Epoch: 174, Train Acc: 0.9533, Test Acc: 0.8421\n",
            "Epoch: 175, Train Acc: 0.9667, Test Acc: 0.8158\n",
            "Epoch: 176, Train Acc: 0.9667, Test Acc: 0.7368\n",
            "Epoch: 177, Train Acc: 0.9733, Test Acc: 0.7895\n",
            "Epoch: 178, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 179, Train Acc: 0.9600, Test Acc: 0.7632\n",
            "Epoch: 180, Train Acc: 0.9733, Test Acc: 0.7632\n",
            "Epoch: 181, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 182, Train Acc: 0.9733, Test Acc: 0.7895\n",
            "Epoch: 183, Train Acc: 0.9667, Test Acc: 0.7632\n",
            "Epoch: 184, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 185, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 186, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 187, Train Acc: 0.9533, Test Acc: 0.7895\n",
            "Epoch: 188, Train Acc: 0.9467, Test Acc: 0.7105\n",
            "Epoch: 189, Train Acc: 0.9467, Test Acc: 0.8421\n",
            "Epoch: 190, Train Acc: 0.9733, Test Acc: 0.7368\n",
            "Epoch: 191, Train Acc: 0.9600, Test Acc: 0.7105\n",
            "Epoch: 192, Train Acc: 0.9533, Test Acc: 0.8421\n",
            "Epoch: 193, Train Acc: 0.9600, Test Acc: 0.7632\n",
            "Epoch: 194, Train Acc: 0.9600, Test Acc: 0.7632\n",
            "Epoch: 195, Train Acc: 0.9600, Test Acc: 0.8158\n",
            "Epoch: 196, Train Acc: 0.9667, Test Acc: 0.8158\n",
            "Epoch: 197, Train Acc: 0.9600, Test Acc: 0.7895\n",
            "Epoch: 198, Train Acc: 0.9800, Test Acc: 0.7632\n",
            "Epoch: 199, Train Acc: 0.9533, Test Acc: 0.8158\n",
            "Epoch: 200, Train Acc: 0.9733, Test Acc: 0.7895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rChlWkjpRGY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce6e398a-e566-45c2-f2e0-92a77d8d8c31"
      },
      "source": [
        "from torch_geometric.nn import GraphConv\n",
        "from torch_geometric.nn import TopKPooling\n",
        "from torch_geometric.nn import SAGPooling\n",
        "import math\n",
        "\n",
        "class GNN_topk(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, ratio):\n",
        "        super(GNN_topk, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)  # TODO\n",
        "        self.conv2 = GraphConv(hidden_channels, hidden_channels) # TODO\n",
        "        #self.pool1 = TopKPooling(hidden_channels, ratio = ratio)\n",
        "        self.pool1 = SAGPooling(hidden_channels, ratio = ratio)\n",
        "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x, edge_index, _,batch,_, score  = self.pool1(x, edge_index, None, batch)\n",
        "        self.score = score, edge_index, batch\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = self.lin(x)\n",
        "      \n",
        "        return x\n",
        "\n",
        "model = GNN_topk(hidden_channels=64, ratio = 0.5)\n",
        "print(model)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GNN_topk(\n",
            "  (conv1): GraphConv(7, 64)\n",
            "  (conv2): GraphConv(64, 64)\n",
            "  (pool1): SAGPooling(GraphConv, 64, ratio=0.5, multiplier=1)\n",
            "  (conv3): GraphConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1SnfOINRGhj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "fa8c207e-b1d8-445c-9561-494920bb6007"
      },
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = GNN_topk(hidden_channels=12, ratio = 0.5)\n",
        "print(model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1, 3):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GNN_topk(\n",
            "  (conv1): GraphConv(7, 12)\n",
            "  (conv2): GraphConv(12, 12)\n",
            "  (pool1): SAGPooling(GraphConv, 12, ratio=0.5, multiplier=1)\n",
            "  (conv3): GraphConv(12, 12)\n",
            "  (lin): Linear(in_features=12, out_features=2, bias=True)\n",
            ")\n",
            "Epoch: 001, Train Acc: 0.6867, Test Acc: 0.5789\n",
            "Epoch: 002, Train Acc: 0.6867, Test Acc: 0.5789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4XqptGT06Zo",
        "outputId": "258f8f7f-706a-4f33-f88b-9437efdbc7c7"
      },
      "source": [
        "model.score"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.9538, 0.9399, 0.9146, 0.9055, 0.8977, 0.9851, 0.9851, 0.9384, 0.9384,\n",
              "         0.9384, 0.9384, 0.9347, 0.9347, 0.9145, 0.9680, 0.9680, 0.9680, 0.9622,\n",
              "         0.9507, 0.9497, 0.9497, 0.9358, 0.9348, 0.9348, 0.9753, 0.9753, 0.9419,\n",
              "         0.9419, 0.9355, 0.9355, 0.9347, 0.9316, 0.9316, 0.9571, 0.9545, 0.9307,\n",
              "         0.9229, 0.9096, 0.9057, 0.9057, 0.9857, 0.9857, 0.9641, 0.9619, 0.9384,\n",
              "         0.9346, 0.9307, 0.9227, 0.9145, 0.9145, 0.9054, 0.9919, 0.9919, 0.9872,\n",
              "         0.9871, 0.9681, 0.9572, 0.9476, 0.9445, 0.9441, 0.9428, 0.9538, 0.9460,\n",
              "         0.9457, 0.9213, 0.9130, 0.9078, 0.9866, 0.9832, 0.9641, 0.9531, 0.9419,\n",
              "         0.9384, 0.9365, 0.9149, 0.9956, 0.9956, 0.9872, 0.9872, 0.9872, 0.9872,\n",
              "         0.9477, 0.9477, 0.9477, 0.9477, 0.9476, 0.9961, 0.9953, 0.9935, 0.9919,\n",
              "         0.9892, 0.9891, 0.9879, 0.9879, 0.9681, 0.9641, 0.9529, 0.9477, 0.9866,\n",
              "         0.9832, 0.9619, 0.9476, 0.9419, 0.9412, 0.9346, 0.9307, 0.9227, 0.9145,\n",
              "         0.9052, 0.9880, 0.9872, 0.9749, 0.9749, 0.9491, 0.9444, 0.9412, 0.9384,\n",
              "         0.9953, 0.9935, 0.9934, 0.9930, 0.9923, 0.9891, 0.9677, 0.9641, 0.9477,\n",
              "         0.9477, 0.9445, 0.9358, 0.9347, 0.9176, 0.9176, 0.8988, 0.8988, 0.9831,\n",
              "         0.9673, 0.9577, 0.9274, 0.9154, 0.9145, 0.9079, 0.9958, 0.9958, 0.9941,\n",
              "         0.9935, 0.9927, 0.9923, 0.9891, 0.9879, 0.9677, 0.9641, 0.9477, 0.9477,\n",
              "         0.9477, 0.9880, 0.9832, 0.9613, 0.9476, 0.9419, 0.9412, 0.9384, 0.9233,\n",
              "         0.9953, 0.9935, 0.9930, 0.9927, 0.9927, 0.9885, 0.9641, 0.9528, 0.9477,\n",
              "         0.9477, 0.9470, 0.9956, 0.9950, 0.9891, 0.9891, 0.9879, 0.9879, 0.9619,\n",
              "         0.9619, 0.9477, 0.9477, 0.9445, 0.9961, 0.9953, 0.9935, 0.9913, 0.9894,\n",
              "         0.9892, 0.9891, 0.9879, 0.9659, 0.9656, 0.9641, 0.9529, 0.9477, 0.9841,\n",
              "         0.9841, 0.9531, 0.9476, 0.9419, 0.9419, 0.9412, 0.9365, 0.9713, 0.9680,\n",
              "         0.9680, 0.9674, 0.9653, 0.9556, 0.9497, 0.9497, 0.9413, 0.9410, 0.9348,\n",
              "         0.9307, 0.9307, 0.9143, 0.9052, 0.9052, 0.8824, 0.9956, 0.9935, 0.9935,\n",
              "         0.9927, 0.9923, 0.9879, 0.9528, 0.9477, 0.9477, 0.9445, 0.9961, 0.9953,\n",
              "         0.9930, 0.9929, 0.9892, 0.9891, 0.9879, 0.9871, 0.9690, 0.9681, 0.9641,\n",
              "         0.9529, 0.9477, 0.9956, 0.9956, 0.9879, 0.9879, 0.9872, 0.9872, 0.9477,\n",
              "         0.9477, 0.9477, 0.9477, 0.9801, 0.9722, 0.9551, 0.9316, 0.9202, 0.9024,\n",
              "         0.8998, 0.9525, 0.9457, 0.9364, 0.9188, 0.9075, 0.8977, 0.9919, 0.9919,\n",
              "         0.9866, 0.9857, 0.9477, 0.9477, 0.9477, 0.9476, 0.9445, 0.9942, 0.9891,\n",
              "         0.9879, 0.9872, 0.9677, 0.9528, 0.9419, 0.9419, 0.9919, 0.9914, 0.9879,\n",
              "         0.9857, 0.9677, 0.9528, 0.9477, 0.9477, 0.9419, 0.9866, 0.9832, 0.9619,\n",
              "         0.9476, 0.9419, 0.9384, 0.9376, 0.9227, 0.9950, 0.9935, 0.9935, 0.9927,\n",
              "         0.9927, 0.9902, 0.9619, 0.9619, 0.9477, 0.9477, 0.9445, 0.9422, 0.9393,\n",
              "         0.9307, 0.9091, 0.8996, 0.8967, 0.7797, 0.9919, 0.9919, 0.9866, 0.9857,\n",
              "         0.9477, 0.9477, 0.9477, 0.9476, 0.9445, 0.9866, 0.9832, 0.9619, 0.9469,\n",
              "         0.9444, 0.9410, 0.9384, 0.9346, 0.9307, 0.9227, 0.9145, 0.9093, 0.9958,\n",
              "         0.9958, 0.9941, 0.9935, 0.9927, 0.9923, 0.9891, 0.9879, 0.9677, 0.9641,\n",
              "         0.9477, 0.9477, 0.9477], grad_fn=<IndexBackward>),\n",
              " tensor([[  3,   4,   4,  ..., 345, 353, 352],\n",
              "         [  4,   3,   0,  ..., 353, 345, 346]]),\n",
              " tensor([ 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,\n",
              "          2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,\n",
              "          4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
              "          6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
              "          8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10,\n",
              "         10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
              "         11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "         13, 13, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16,\n",
              "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19,\n",
              "         19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21,\n",
              "         21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "         23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25,\n",
              "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26,\n",
              "         26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29,\n",
              "         29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31,\n",
              "         31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33,\n",
              "         33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35,\n",
              "         35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37,\n",
              "         37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SGnbvhvw-vR"
      },
      "source": [
        "def get_scores(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  \n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tBMhOrq4JKw"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this chapter, you have learned how to apply GNNs to the task of graph classification.\n",
        "You have learned how graphs can be batched together for better GPU utilization, and how to apply readout layers for obtaining graph embeddings rather than node embeddings.\n",
        "\n",
        "In the next session, you will learn how you can utilize PyTorch Geometric to let Graph Neural Networks scale to single large graphs.\n",
        "\n",
        "[Next: Scaling Graph Neural Networks](https://colab.research.google.com/drive/1XAjcjRHrSR_ypCk_feIWFbcBKyT4Lirs)"
      ]
    }
  ]
}